{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requerements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch windows cuda (nvidia)\n",
    "!pip install requirements.txt\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pyaudio\n",
    "import librosa\n",
    "import asyncio\n",
    "import threading\n",
    "import numpy as np\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, AutoProcessor, AutoModelForCTC, TFWav2Vec2ForCTC, \\\n",
    "                         AutoTokenizer, AutoFeatureExtractor, T5ForConditionalGeneration, T5Tokenizer\n",
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO когда санкции снимут\n",
    "# import os\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./google_cred.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auto-translator\n",
    "Program for auto translate any video in real time\n",
    "\n",
    "## ПРЕДИСЛОВИЕ\n",
    "\n",
    "#### Перед тем, как запускать прогу, необходимо:\n",
    "\n",
    "1) установить virtual audio cable\n",
    "\n",
    "2) в sound mixer options для всех выбрать defaul input = Line 1(virtual audio cable) ( можете выбрать любой удобный вам кабель)\n",
    "\n",
    "3) затем для нужной программы (окна) в output выбрать тот же кабель (Line 1, например) \n",
    "\n",
    "4) вызвать код для нахождения подключённых аудиоустройств:\n",
    "\n",
    "   ```recorder = pyaudio.PyAudio()```\n",
    "\n",
    "   ```for i in range(recorder.get_device_count()):```\n",
    "   \n",
    "   ```    print(i, recorder.get_device_info_by_index(i))```\n",
    "\n",
    "5) выбрать подходящее аудиоустройство (для записи должно быть устройство Line 1, у которого ```'maxInputChannels' != 0```,\n",
    "  а для вывода должно быть устройство (наушники, колонки), у которого ```'maxOutputChannels' != 0```\n",
    "\n",
    "6) и когда открываете потоки для записи/воспроизведения звука в kwargs передаёте нужный вам индекс в переменную ```input_device_index```, аналогично для ```input_device_index``` в воспроизводящем потоке\n",
    "\n",
    "7) после запуска у нас звук будет перенаправляться так: приложение->Line_1_output->Line_1_input->Наша прога->Вывод на выбранное устройство.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioChanel():\n",
    "    def __init__(self):\n",
    "        #change this according to your model\n",
    "        self.chunk = 1024\n",
    "        self.format = pyaudio.paInt16\n",
    "        self.channels = 1#2\n",
    "        self.rate = 16000\n",
    "        self.recorder = pyaudio.PyAudio()\n",
    "        self.frames = []\n",
    "        self.seconds = 2\n",
    "        # Открыть поток для записи\n",
    "        #1 {'index': 1, 'structVersion': 2, 'name': 'Line 1 (Virtual Audio Cable)', 'hostApi': 0, 'maxInputChannels': 2, \n",
    "        #   'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, \n",
    "        #   'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
    "        self.input_stream = self.recorder.open(format=self.format,\n",
    "                                          channels=self.channels,\n",
    "                                          rate=self.rate,\n",
    "                                          input=True,\n",
    "                                          frames_per_buffer=self.chunk,\n",
    "                                          input_device_index=1) #0,1 - work\n",
    "        # Открыть поток для воспроизведения\n",
    "        #5 {'index': 5, 'structVersion': 2, 'name': '... (Realtek)', 'hostApi': 0, 'maxInputChannels': 0, \n",
    "        #   'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, \n",
    "        #   'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
    "        self.output_stream = self.recorder.open(format=self.format,\n",
    "                                           channels=self.channels,\n",
    "                                           rate=self.rate,\n",
    "                                           output=True,\n",
    "                                           frames_per_buffer=self.chunk,\n",
    "                                           input_device_index=5) #5- work\n",
    "        \n",
    "        \n",
    "    def record(self):\n",
    "        while True:\n",
    "            data = self.input_stream.read(self.chunk)\n",
    "            self.frames.append(data)\n",
    "\n",
    "    def play(self, audio = None):\n",
    "        output_stream = self.recorder.open(format=self.format,\n",
    "                                           channels=self.channels,\n",
    "                                           rate=self.rate,\n",
    "                                           output=True,\n",
    "                                           frames_per_buffer=self.chunk,\n",
    "                                           input_device_index=5) #5- work\n",
    "        match audio:\n",
    "            case list():\n",
    "                for frame in audio:\n",
    "                    output_stream.write(frame)\n",
    "            case _:\n",
    "                output_stream.write(audio.tobytes())\n",
    "\n",
    "    def play_default(self):\n",
    "        output_stream = self.recorder.open(format=self.format,\n",
    "                                           channels=self.channels,\n",
    "                                           rate=self.rate,\n",
    "                                           output=True,\n",
    "                                           frames_per_buffer=self.chunk,\n",
    "                                           input_device_index=5) #5- work\n",
    "        with threading.Lock():\n",
    "            to_play = list(self.frames)\n",
    "        for frame in to_play:\n",
    "            output_stream.write(frame)\n",
    "    \n",
    "    def get(self):\n",
    "        with threading.Lock():\n",
    "            return list(self.frames)\n",
    "        \n",
    "        \n",
    "    def close(self):\n",
    "        self.input_stream.stop_stream()\n",
    "        self.input_stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self):\n",
    "        self.audio = AudioChanel()\n",
    "        self.device = torch.device('cuda')\n",
    "        #you may use your models instead\n",
    "        self.processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "        self.model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\").to(self.device)\n",
    "        self.feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "        self.spell = SpellChecker()\n",
    "        self.nlp = spacy.load('en_core_web_sm')#en_core_web_trf\n",
    "        self.PASS_VAR = False\n",
    "\n",
    "        #the worst model EVER\n",
    "        model_name = 'utrobinmv/t5_translate_en_ru_zh_small_1024'# small, large and base\n",
    "        self.model_translate = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "        self.tokenizer_translate = T5Tokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        language = 'ru'\n",
    "        model_id = 'v4_ru'\n",
    "        self.sample_rate = 48000\n",
    "        self.speaker = 'kseniya'\n",
    "        \n",
    "        self.model_voice, _ = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                             model='silero_tts',\n",
    "                                             language=language,\n",
    "                                             speaker=model_id)\n",
    "        self.model_voice.to(self.device)\n",
    "        self.to_play = []\n",
    "    \n",
    "    def correcting(self,sent):\n",
    "        to_spell = sent.split()\n",
    "        corrected_words = [self.spell.correction(word) for word in to_spell]\n",
    "        return ' '.join((word if word is not None else to_spell[idx]) for idx, word in enumerate(corrected_words))\n",
    "\n",
    "    def send_to_play(self):\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "            with threading.Lock():\n",
    "                copy_to_play = list(self.to_play)\n",
    "            while len(copy_to_play):\n",
    "                to_play = copy_to_play[0]\n",
    "                translation = threading.Thread(target=self.audio.play,args=(to_play[0],))\n",
    "                original = threading.Thread(target=self.audio.play,args=(to_play[1],))\n",
    "                \n",
    "                translation.start()\n",
    "                original.start()\n",
    "                \n",
    "                translation.join()\n",
    "                original.join()\n",
    "                with threading.Lock():\n",
    "                    del self.to_play[0]\n",
    "                    del copy_to_play[0]\n",
    "    \n",
    "    async def run(self):\n",
    "        #start recording\n",
    "        _ = threading.Thread(target=self.audio.record).start()\n",
    "        _ = threading.Thread(target=self.send_to_play).start()\n",
    "        \n",
    "        # await asyncio.sleep(10)\n",
    "        last_state = ''\n",
    "        while True:\n",
    "            '''\n",
    "            PART 1\n",
    "            RECORDING\n",
    "            description: record every 2 seconds of audio from PC\n",
    "            '''\n",
    "            await asyncio.sleep(2)\n",
    "            time = datetime.now()\n",
    "            frames = self.audio.get()[:200]\n",
    "            to_model = np.frombuffer(b''.join(frames), dtype=np.int16)\n",
    "            end_1 = datetime.now()\n",
    "            # print('end_1: ', end_1)\n",
    "            '''\n",
    "            PART 2\n",
    "            CONVERTING AUDIO TO TEXT\n",
    "            description: put audio into model and get recognized words\n",
    "            '''\n",
    "            input_values = self.processor(to_model, sampling_rate = self.audio.rate, return_tensors=\"pt\").input_values  # Batch size 1\n",
    "            logits = self.model(input_values.to(torch.float).to(self.device)).logits\n",
    "            predicted_ids = torch.argmax(logits, axis=-1)\n",
    "            \n",
    "            outputs = self.tokenizer.decode(predicted_ids[0], output_word_offsets=True)\n",
    "            # compute `time_offset` in seconds as product of downsampling ratio and sampling_rate\n",
    "            time_offset = self.model.config.inputs_to_logits_ratio / self.feature_extractor.sampling_rate\n",
    "            \n",
    "            word_offsets = [\n",
    "                {\n",
    "                    \"word\": d[\"word\"],\n",
    "                    \"start_time\": round(d[\"start_offset\"] * time_offset, 2),\n",
    "                    \"end_time\": round(d[\"end_offset\"] * time_offset, 2),\n",
    "                }\n",
    "                for d in outputs.word_offsets\n",
    "            ]\n",
    "            end_2 = datetime.now()\n",
    "            print('end_2: ', end_2-end_1)\n",
    "            '''\n",
    "            PART 3\n",
    "            FIND SENTENCIES IN THE OUTPUT TEXT\n",
    "            description: find grammar parts in output text for building whole sentences\n",
    "            '''\n",
    "            text = ' '.join([word['word'] for word in word_offsets])\n",
    "            fixed = self.correcting(text)\n",
    "            print('Full recorded text: ', text)\n",
    "            if last_state == '':\n",
    "                last_state = text\n",
    "            else:\n",
    "                if last_state == text:\n",
    "                    self.PASS_VAR = True\n",
    "                last_state = text\n",
    "                \n",
    "            doc = self.nlp(fixed)\n",
    "    \n",
    "            end_3 = datetime.now()\n",
    "            print('end_3: ', end_3-end_2)\n",
    "            '''\n",
    "            PART 4\n",
    "            TRANSLATE SENTENCE INTO RUSSIAN (or any other language)\n",
    "            description: translate one of the list, because we should be sure about full context\n",
    "            '''\n",
    "            sents = list(doc.sents)\n",
    "            if len(sents)<=1 and not self.PASS_VAR:\n",
    "                continue\n",
    "            self.PASS_VAR = False\n",
    "            print(sents)\n",
    "            \n",
    "            prefix = 'translate to ru: '\n",
    "            ### delete part of audio.frames list\n",
    "            with threading.Lock():\n",
    "                idx_del = len(sents[0].text.split())-1 if len(sents[0].text.split())==len(word_offsets) else len(sents[0].text.split())\n",
    "                to_del = int(word_offsets[idx_del]['end_time']*self.audio.rate/self.audio.chunk)\n",
    "                play_background = self.audio.frames[:to_del+1]\n",
    "                del self.audio.frames[:to_del]\n",
    "            ###\n",
    "            src_text = prefix + sents[0].text\n",
    "            \n",
    "            # translate Englosh to Russian\n",
    "            input_ids = self.tokenizer_translate(src_text, return_tensors=\"pt\")\n",
    "            \n",
    "            generated_tokens = self.model_translate.generate(**input_ids.to(self.device))\n",
    "            \n",
    "            result = self.tokenizer_translate.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            end_4 = datetime.now()\n",
    "            print('end_4: ', end_4-end_3)\n",
    "            '''\n",
    "            PART 5\n",
    "            VOICEOVER OF TEXT AND PLAY\n",
    "            description: voice translated text\n",
    "            '''\n",
    "            print(result[0])\n",
    "            if not len(result[0]):\n",
    "                continue\n",
    "                  \n",
    "            audio = self.model_voice.apply_tts(text=result[0],\n",
    "                        speaker=self.speaker,\n",
    "                        sample_rate=self.sample_rate)\n",
    "            \n",
    "            audio_numpy = audio.cpu().numpy()\n",
    "            audio_resampled = librosa.resample(audio_numpy, orig_sr=self.sample_rate, \n",
    "                                               target_sr=self.audio.rate, res_typestr='fft')\n",
    "            audio_int16 = (audio_resampled * 32767).astype(np.int16)\n",
    "            end_5 = datetime.now()\n",
    "            print('end_5: ', end_5-end_4)\n",
    "            # self.audio.play(audio_int16)\n",
    "            with threading.Lock():\n",
    "                self.to_play.append((audio_int16,frames[:to_del]))\n",
    "            # _ = threading.Thread(target=self.audio.play, args=(play_background,)).start()\n",
    "            \n",
    "a = Agent()\n",
    "await a.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
